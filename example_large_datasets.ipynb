{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173823d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nudge import NUDGEM, NUDGEN\n",
    "from knnretriever import kNNRetriever\n",
    "from utils import calc_metrics_batch, load_hf_datasets, embed_data_and_query_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06f46ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "loading qs train\n",
      "loading qs dev\n",
      "loading qs test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  38%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 89775/238482 [24:49<31:11, 79.44it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Batches:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 165476/238482 [40:42<14:27, 84.19it/s]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 238482/238482 [55:01<00:00, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding qs train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1932/1932 [00:22<00:00, 86.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding qs dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:02<00:00, 88.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding qs test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:03<00:00, 87.32it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'nq'\n",
    "dataset, query_sets = load_hf_datasets(dataset_name)\n",
    "data_emb, query_sets = embed_data_and_query_sets(dataset, query_sets, \"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f92e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nontest_index = -1\n",
    "for split in [\"train\", \"dev\"]:\n",
    "    max_nontest_index = max(np.array([indx for curr_q_ans_indx in query_sets[split]['q_ans_indx'] for indx in curr_q_ans_indx]).max()+1, max_nontest_index)\n",
    "nontrain_dataset = dataset.loc[max_nontest_index:]\n",
    "if nontrain_dataset.shape[0] == 0:\n",
    "    embeddings = data_emb\n",
    "    nontrain_embeddings  = None\n",
    "else:\n",
    "    embeddings = data_emb[:max_nontest_index]\n",
    "    nontrain_embeddings = data_emb[max_nontest_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c392c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating G\n",
      "Finding gamma\n"
     ]
    }
   ],
   "source": [
    "nudgen =  NUDGEN()\n",
    "new_embs_nudgen = nudgen.finetune_embeddings(embeddings, query_sets['train'], query_sets['dev'], (nontrain_embeddings, None))\n",
    "nudge_nret = kNNRetriever(new_embs_nudgen, nontrain_embeddings)\n",
    "nudge_n_res = nudge_nret.retrieve_topk_from_emb_batch(k=10, q_embeds=query_sets['test']['q_embs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f858cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating G\n",
      "Finding gamma\n"
     ]
    }
   ],
   "source": [
    "nudgem =  NUDGEM()\n",
    "new_embs_nudgem = nudgem.finetune_embeddings(embeddings, query_sets['train'], query_sets['dev'],(nontrain_embeddings, None))\n",
    "nudge_mret = kNNRetriever(new_embs_nudgem, nontrain_embeddings,dist_metric='dot')\n",
    "nudge_m_res = nudge_mret.retrieve_topk_from_emb_batch(k=10, q_embeds=query_sets['test']['q_embs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4833fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ft_ret = kNNRetriever(embeddings, nontrain_embeddings)\n",
    "no_ft_res = no_ft_ret.retrieve_topk_from_emb_batch(k=10, q_embeds=query_sets['test']['q_embs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e158bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fine-Tuning recall@10: 36.3, ndcg@10: 21.2\n",
      "NUDGE-M recall@10: 43.6, ndcg@10: 38.6\n",
      "NUDGE-N recall@10: 57.8, ndcg@10: 45.9\n"
     ]
    }
   ],
   "source": [
    "metrics = [('recall',10), ('ndcg',10)]\n",
    "no_ft_accs = calc_metrics_batch(metrics,no_ft_res, query_sets['test']['q_ans_indx'], query_sets['test']['q_ans_indx_rel'])\n",
    "nudgem_accs = calc_metrics_batch(metrics,nudge_m_res, query_sets['test']['q_ans_indx'], query_sets['test']['q_ans_indx_rel'])\n",
    "nudgen_accs = calc_metrics_batch(metrics,nudge_n_res, query_sets['test']['q_ans_indx'], query_sets['test']['q_ans_indx_rel'])\n",
    "print(f\"No Fine-Tuning {metrics[0][0]}@{metrics[0][1]}: {no_ft_accs[0]*100:.1f}, {metrics[1][0]}@{metrics[1][1]}: {no_ft_accs[1]*100:.1f}\")\n",
    "print(f\"NUDGE-M {metrics[0][0]}@{metrics[0][1]}: {nudgem_accs[0]*100:.1f}, {metrics[1][0]}@{metrics[1][1]}: {nudgem_accs[1]*100:.1f}\")\n",
    "print(f\"NUDGE-N {metrics[0][0]}@{metrics[0][1]}: {nudgen_accs[0]*100:.1f}, {metrics[1][0]}@{metrics[1][1]}: {nudgen_accs[1]*100:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842ea93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
